Running Model with pred_len 192...
Args in experiment:
Namespace(task_name='long_term_forecast', is_training=1, model_id='Exchange_96_192', model='FEDformer', data='custom', root_path='./dataset/exchange_rate/', data_path='exchange_rate.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, top_k=5, num_kernels=6, enc_in=8, dec_in=8, c_out=8, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2)
Use GPU: cuda:0
fourier enhanced block used!
modes=32, index=[2, 3, 4, 5, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 23, 25, 26, 28, 31, 32, 34, 35, 37, 38, 39, 40, 42, 43, 44, 46]
fourier enhanced block used!
modes=32, index=[0, 2, 6, 8, 10, 13, 14, 21, 22, 23, 28, 34, 35, 36, 42, 44, 45, 52, 55, 64, 66, 67, 68, 69, 72, 73, 83, 93, 98, 115, 117, 119]
 fourier enhanced cross attention used!
modes_q=32, index_q=[1, 5, 8, 12, 15, 20, 22, 26, 28, 30, 31, 36, 37, 46, 48, 55, 63, 64, 66, 77, 78, 81, 82, 85, 88, 90, 91, 94, 97, 99, 106, 107]
modes_kv=32, index_kv=[0, 1, 4, 6, 7, 11, 12, 13, 14, 17, 18, 19, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 43, 44, 45, 46]
>>>>>>>start training : long_term_forecast_Exchange_96_192_FEDformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5024
val 569
test 1326
	iters: 100, epoch: 1 | loss: 0.4482838
	speed: 0.4346s/iter; left time: 639.2598s
Epoch: 1 cost time: 68.02295470237732
Epoch: 1, Steps: 157 | Train Loss: 0.3667777 Vali Loss: 0.3053553 Test Loss: 0.2627565
Validation loss decreased (inf --> 0.305355).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3680585
	speed: 1.5822s/iter; left time: 2079.0524s
Epoch: 2 cost time: 67.1651086807251
Epoch: 2, Steps: 157 | Train Loss: 0.3278942 Vali Loss: 0.3025010 Test Loss: 0.2645274
Validation loss decreased (0.305355 --> 0.302501).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3804441
	speed: 1.5694s/iter; left time: 1815.7451s
Epoch: 3 cost time: 67.05859518051147
Epoch: 3, Steps: 157 | Train Loss: 0.3242683 Vali Loss: 0.3024076 Test Loss: 0.2668613
Validation loss decreased (0.302501 --> 0.302408).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2384601
	speed: 1.5598s/iter; left time: 1559.7930s
Epoch: 4 cost time: 66.97646307945251
Epoch: 4, Steps: 157 | Train Loss: 0.3227018 Vali Loss: 0.2937291 Test Loss: 0.2754927
Validation loss decreased (0.302408 --> 0.293729).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.4507155
	speed: 1.5591s/iter; left time: 1314.2985s
Epoch: 5 cost time: 67.02051496505737
Epoch: 5, Steps: 157 | Train Loss: 0.3214498 Vali Loss: 0.3045214 Test Loss: 0.2640955
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3297501
	speed: 1.5663s/iter; left time: 1074.4570s
Epoch: 6 cost time: 66.96116638183594
Epoch: 6, Steps: 157 | Train Loss: 0.3210741 Vali Loss: 0.2923164 Test Loss: 0.2772539
Validation loss decreased (0.293729 --> 0.292316).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.2946428
	speed: 1.5712s/iter; left time: 831.1761s
Epoch: 7 cost time: 66.9365119934082
Epoch: 7, Steps: 157 | Train Loss: 0.3209725 Vali Loss: 0.2986057 Test Loss: 0.2703454
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.4042727
	speed: 1.5647s/iter; left time: 582.0525s
Epoch: 8 cost time: 66.97420024871826
Epoch: 8, Steps: 157 | Train Loss: 0.3207768 Vali Loss: 0.2980047 Test Loss: 0.2704427
EarlyStopping counter: 2 out of 3
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3222887
	speed: 1.5643s/iter; left time: 336.3204s
Epoch: 9 cost time: 66.97626090049744
Epoch: 9, Steps: 157 | Train Loss: 0.3206971 Vali Loss: 0.2987670 Test Loss: 0.2709897
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_Exchange_96_192_FEDformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1326
test shape: (1326, 1, 192, 8) (1326, 1, 192, 8)
test shape: (1326, 192, 8) (1326, 192, 8)
mse:0.27725380659103394, mae:0.383836030960083